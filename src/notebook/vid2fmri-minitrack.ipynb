{"cells":[{"cell_type":"markdown","metadata":{"id":"nZec1vCEyjlp"},"source":["## Environment setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":234,"status":"ok","timestamp":1629030606459,"user":{"displayName":"Mianaki Kowalski","photoUrl":"","userId":"15248163512885521992"},"user_tz":-120},"id":"Jn7D0IMai7cg","outputId":"42962bbd-0deb-4a82-e753-e0ece7689087"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1629030606675,"user":{"displayName":"Mianaki Kowalski","photoUrl":"","userId":"15248163512885521992"},"user_tz":-120},"id":"7HhapcaLzOej","outputId":"fdd184e7-8e98-4056-b41d-f1d8a949133c"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12538,"status":"ok","timestamp":1629030619473,"user":{"displayName":"Mianaki Kowalski","photoUrl":"","userId":"15248163512885521992"},"user_tz":-120},"id":"97qf2P2jc3V3","outputId":"1207b7ba-a319-4115-905d-5eec8e6485f8"},"outputs":[],"source":["!pip install decord\n","!pip install albumentations -U\n","!pip install git+https://github.com/rwightman/pytorch-image-models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LzG2JT_ytN1O"},"outputs":[],"source":["import sys\n","sys.path.insert(1, \"/gdrive/My Drive/Projects/algonauts/src/mini-track/src_new/\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ijwwDSYezpv8"},"outputs":[],"source":["import os\n","import numpy as np\n","\n","import torch\n","import timm\n","from tqdm.notebook import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JHuyFwwZ4lO7"},"outputs":[],"source":["import settings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SAKnxuhSzjj0"},"outputs":[],"source":["!mkdir {settings.DATA_FOLDER}\n","!unzip -qq {settings.PROJECT_FOLDER}data/participants_data.zip -d {settings.DATA_FOLDER}"]},{"cell_type":"markdown","metadata":{"id":"S53-hJsxxxvE"},"source":["## Training helper functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AcEM3bVShAd9"},"outputs":[],"source":["import model.utils as model_utils\n","import runner.utils as runner_utils\n","import data.utils as data_utils\n","\n","import data.handler as data_handler\n","from data.dataset import VidDataset, VidFMRIDataset\n","\n","from runner import runner_gpu as runner\n","from runner.loss import WeightedMSELoss\n","from runner.metric import vectorized_correlation\n","\n","from torch.utils.data import DataLoader"]},{"cell_type":"markdown","metadata":{"id":"8bfVYlEQAm69"},"source":["### Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FqC3CYXPesmE"},"outputs":[],"source":["def append_to_history(history_dict, target, output, loss, score):\n","    history_dict[\"loss\"].append(loss)\n","    history_dict[\"score\"].append(score)\n","    history_dict[\"outputs\"].append(output)\n","    history_dict[\"targets\"].append(target)\n","\n","\n","def train_and_validate(args):\n","    # SEED and split\n","    runner_utils.seed_everything(seed=settings.SEED)\n","\n","    train_vid_files = args.vid_files[0:900]\n","    valid_vid_files = args.vid_files[900:1000]\n","    train_fmri_data = args.fmri_data[0:900, :, :]\n","    valid_fmri_data = args.fmri_data[900:1000, :, :]\n","\n","    # create model\n","    model = model_utils.get_model(output_size=args.fmri_voxel_total, **args.model_params)\n","    model = model.to(args.device)\n","    # train data loader\n","    train_dataset = VidFMRIDataset(train_vid_files, train_fmri_data, transform=data_utils.get_train_transform(), fmri_transform=\"combination_augment\")\n","    train_loader = DataLoader(train_dataset, num_workers=args.num_workers, batch_size=args.batch_size, shuffle=True)\n","    # valid loader\n","    valid_dataset = VidFMRIDataset(valid_vid_files, valid_fmri_data, transform=data_utils.get_test_transform(), fmri_transform=\"mean_over_rep\")\n","    valid_loader = DataLoader(valid_dataset, num_workers=args.num_workers, batch_size=1, shuffle=False)\n","    # loss, optimizer and scheduler\n","    train_criterion = WeightedMSELoss(reduction=\"mean\")\n","    valid_criterion = torch.nn.MSELoss()\n","    optimizer = args.optimizer(model.parameters(), lr=args.lr, **args.optimizer_params)\n","    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n","                    optimizer,\n","                    max_lr=args.lr,\n","                    epochs=args.epochs,\n","                    steps_per_epoch=len(train_loader),\n","                    div_factor=10,\n","                    final_div_factor=1,\n","                    pct_start=0.1,\n","                    anneal_strategy=\"cos\",\n","                )\n","    # history dicts\n","    train_history = {\"loss\": [], \"score\": [], \"outputs\": [], \"targets\": []}\n","    valid_history = {\"loss\": [], \"score\": [], \"outputs\": [], \"targets\": []}\n","    model_history = {\"best\": {\"state\" : None, \"score\": 0, \"epoch\": -1}, \n","                     \"last\": {\"state\" : None, \"score\": 0, \"epoch\": -1}}\n","    \n","    # train - validate - save\n","    for epoch in range(1, args.epochs +1):\n","        targets_all, outputs_all, loss, score = runner.train_epoch(args, model, train_loader, train_criterion, optimizer, scheduler, epoch)\n","        append_to_history(train_history, None, None, loss, score)\n","        runner_utils.print_score(outputs_all, targets_all, args.fmri_mapping, \"\\n\\t\")\n","\n","        targets_all, outputs_all, loss, score = runner.validate(args, model, valid_loader, valid_criterion)\n","        append_to_history(valid_history, targets_all, outputs_all, loss, score)\n","        runner_utils.print_score(outputs_all, targets_all, args.fmri_mapping, \"\\t\")\n","\n","        model_history[\"last\"][\"state\"] = model.state_dict()\n","        model_history[\"last\"][\"score\"] = score\n","        model_history[\"last\"][\"epoch\"] = epoch\n","\n","        if (score > model_history[\"best\"][\"score\"]):\n","            model_history[\"best\"][\"state\"] = model.state_dict()\n","            model_history[\"best\"][\"score\"] = score\n","            model_history[\"best\"][\"epoch\"] = epoch\n","\n","        output_history = {\"train\": train_history, \"valid\": valid_history, \"mapping\": args.fmri_mapping}\n","        data_handler.save_dict(output_history, args.output_valid_fn)\n","        torch.save(model_history, args.output_model_fn)\n","\n","    args.model_history = model_history\n","    args.output_history = output_history"]},{"cell_type":"markdown","metadata":{"id":"fzO_CLlCApqY"},"source":["### Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3TGp0R3vG-CM"},"outputs":[],"source":["def evaluate(args):\n","    valid_vid_files = args.vid_files[900:1000]\n","    valid_fmri_data = args.fmri_data[900:1000, :, :]\n","\n","    valid_dataset = VidFMRIDataset(valid_vid_files, valid_fmri_data, transform=data_utils.get_test_transform(), fmri_transform=\"mean_over_rep\")\n","    valid_loader = DataLoader(valid_dataset, num_workers=args.num_workers, batch_size=1, shuffle=False)\n","\n","    model_state = torch.load(args.output_model_fn)\n","    model_state = model_state[\"last\"][\"state\"]\n","\n","    model = model_utils.get_model(output_size=args.fmri_voxel_total, **args.model_params)\n","    model = model.to(args.device)\n","    model.load_state_dict(model_state)\n","\n","    valid_criterion = torch.nn.MSELoss()\n","    targets_all, outputs_all, loss, score = runner.validate(args, model, valid_loader, valid_criterion)\n","    runner_utils.print_score(outputs_all, targets_all, args.fmri_mapping, \"\\t\")"]},{"cell_type":"markdown","metadata":{"id":"ADK2lJMyArgK"},"source":["### Predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TQcFO0dCebun"},"outputs":[],"source":["def predict(args):\n","    # data and dataset\n","    test_vid_files = args.test_vid_files\n","    test_dataset = VidDataset(test_vid_files, transform=data_utils.get_test_transform())\n","    test_loader = DataLoader(test_dataset, num_workers=args.num_workers, batch_size=1, shuffle=False)\n","\n","    # model\n","    model_state = torch.load(args.output_model_fn)\n","    model_state = model_state[\"last\"][\"state\"]\n","\n","    model = model_utils.get_model(output_size=args.fmri_voxel_total, **args.model_params)\n","    model = model.to(args.device)\n","    model.load_state_dict(model_state)\n","\n","    # predict\n","    t = tqdm(test_loader)\n","    model.eval()\n","    outputs_all = []\n","    with torch.no_grad():\n","        for i, sample in enumerate(t):\n","            input  = sample['vid_data'].to(args.device)\n","            fps    = sample['fps'].to(args.device)\n","            output = model(input, fps)\n","            outputs_all.extend(output.detach().cpu().numpy())\n","    \n","    output = {\"fmri_data\": outputs_all, \"mapping\": args.fmri_mapping}\n","    data_handler.save_dict(output, args.output_fn)"]},{"cell_type":"markdown","metadata":{"id":"vp8Jf4FgAtYS"},"source":["### Setup and run"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VZTsOCv4inSu"},"outputs":[],"source":["def generate_model_name(model_params):\n","    return f\"{model_params['model_type']}-{model_params['backbone_name']}-{model_params['embed_size']}\"\n","\n","def generate_model_run_name(model_name, sub, rois):\n","    return f\"{model_name}_{sub}_{'-'.join(rois)}\"\n","\n","def run_sub_roi(args, sub, train_flag=False, evaluate_flag=False, predict_flag=False):\n","    print(f\"Running {sub}: train = {train_flag}, evaluate = {evaluate_flag}, predict = {predict_flag}\")\n","\n","    fmri_data = args.fmri_data[sub]\n","\n","    # subject specific setup\n","    args.sub = sub\n","    args.rois = list(fmri_data[\"mapping\"].keys())\n","    args.fmri_mapping = fmri_data[\"mapping\"]\n","    args.fmri_data = fmri_data[\"data\"]\n","    args.fmri_voxel_total = np.shape(args.fmri_data)[2]\n","\n","    args.model_name = generate_model_name(args.model_params)\n","    model_run_name = generate_model_run_name(args.model_name, args.sub, args.rois)\n","    args.output_fn = f\"{settings.OUTPUT_FOLDER}output_{model_run_name}.pkl\"\n","    args.output_valid_fn = f\"{settings.OUTPUT_FOLDER}output_valid_{model_run_name}.pkl\"\n","    args.output_model_fn = f\"{settings.OUTPUT_FOLDER}model_{model_run_name}.pt\"\n","\n","    if train_flag:\n","        print(f\"Training: {model_run_name}\")\n","        print(args.fmri_mapping)\n","        train_and_validate(args)\n","\n","    if evaluate_flag:\n","        print(f\"Evaluating: {model_run_name}\")\n","        evaluate(args)\n","    \n","    if predict_flag:\n","        print(f\"Predicting: {model_run_name}\")\n","        predict(args)\n","\n","    return args"]},{"cell_type":"markdown","metadata":{"id":"eEOCzTSf4JT5"},"source":["## Train models and predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"13ZGXtIjAxFu"},"outputs":[],"source":["fmri_data, train_vid_files, test_vid_files = data_utils.get_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yf9npVfe5SOd"},"outputs":[],"source":["class base_args:\n","    vid_files = train_vid_files\n","    test_vid_files = test_vid_files\n","    fmri_data = fmri_data\n"," \n","    lr = 1e-3\n","    epochs = 4\n","    batch_size = 4\n","    num_workers = 2\n","    device = ('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1629030623573,"user":{"displayName":"Mianaki Kowalski","photoUrl":"","userId":"15248163512885521992"},"user_tz":-120},"id":"kMargT3e4t5U","outputId":"0b47d2ad-df0d-496b-cf58-d020e438bdb8"},"outputs":[],"source":["class args(base_args):\n","    model_params = {\n","        \"embed_size\": 512,\n","        \"model_type\": \"cnn-stats-adapt-1\",\n","        \"backbone_name\": \"eca_nfnet_l0\",\n","        \"linear_pool\": None,\n","        \"adaptive_pool\": 1,\n","        \"rnn_features\": False,\n","    }\n"," \n","    optimizer = torch.optim.Adam\n","    optimizer_params = {}\n"," \n","for sub in settings.subs:\n","    _ = run_sub_roi(args(), sub, train_flag=True, predict_flag=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EYdkJElz5CK7","outputId":"d17fe584-bf91-43cc-acd0-d12274a490ca"},"outputs":[],"source":["class args(base_args):\n","    model_params = {\n","        \"embed_size\": 1024,\n","        \"model_type\": \"cnn-rnn-adapt-1-lin-6\",\n","        \"backbone_name\": \"resnet50\",\n","        \"linear_pool\": 6,\n","        \"adaptive_pool\": 1,\n","        \"rnn_features\": True,\n","    }\n"," \n","    optimizer = torch.optim.AdamW\n","    optimizer_params = {\n","        \"weight_decay\": 0.02\n","    }\n"," \n","for sub in settings.subs:\n","    _ = run_sub_roi(args(), sub, train_flag=True, predict_flag=True)"]},{"cell_type":"markdown","metadata":{"id":"uwEyYMS_BHKA"},"source":["## Ensemble predictions and create submission"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H52vpVymZEX_"},"outputs":[],"source":["import zipfile\n","\n","model_names = [\"cnn-stats-adapt-1\", \"cnn-rnn-adapt-1-lin-6\"]\n","predictions = {}\n","\n","for i, model_name in enumerate(model_names):\n","    predictions[model_name] = {}\n","\n","    for sub in settings.subs: \n","        model_full_name = f\"{model_name}_{sub}_{'-'.join(settings.ROIs)}\"\n","        args.output_fn = f\"{settings.OUTPUT_FOLDER}output_{model_full_name}.pkl\"\n","        preds = data_handler.load_dict(args.output_fn)\n","        predictions[model_name][sub] = preds\n","\n","\n","def get_roi_data(data, mapping, ROI):\n","    data = np.array(data)\n","    roi_mapping = mapping[ROI]\n","    return data[:, roi_mapping[0]:roi_mapping[1]]\n","\n","\n","results = {}\n","for ROI in settings.ROIs:\n","    ROI_results = {}\n","    for sub in settings.subs:\n","        ROI_results[sub] = None\n","        for model_name in model_names:\n","            if ROI_results[sub] is None:\n","                ROI_results[sub] = get_roi_data(predictions[model_name][sub][\"fmri_data\"], \n","                                                predictions[model_name][sub][\"mapping\"], \n","                                                ROI)\n","            else:\n","                ROI_results[sub] += get_roi_data(predictions[model_name][sub][\"fmri_data\"], \n","                                                 predictions[model_name][sub][\"mapping\"], \n","                                                 ROI)\n","            \n","            ROI_results[sub] /= len(model_names)\n","\n","    results[ROI] = ROI_results\n","\n","output_file = \"/home/\" + settings.track\n","\n","data_handler.save_dict(results, output_file + \".pkl\")\n","zipped_results = zipfile.ZipFile(output_file + \".zip\", 'w')\n","zipped_results.write(output_file + \".pkl\", settings.track + \".pkl\")\n","zipped_results.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-FhFf4jxJADU"},"outputs":[],"source":["!mv {output_file}.zip {settings.OUTPUT_FOLDER}"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"vid2fmri-minitrack.ipynb","provenance":[{"file_id":"13hyfPYFdIr8Ij0jxOToclKoJOph82onq","timestamp":1628243331086}],"toc_visible":true},"interpreter":{"hash":"b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"},"kernelspec":{"display_name":"Python 3.8.5 64-bit ('base': conda)","name":"python3"},"language_info":{"name":"python","version":""}},"nbformat":4,"nbformat_minor":0}